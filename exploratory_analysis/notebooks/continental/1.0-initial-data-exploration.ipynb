{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600349755952",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Initial data exploration\n",
    "Data is available in a `CSV` file. In this module we:\n",
    "\n",
    "* Show how to load src module, containing additional functions for data manipulation\n",
    "* Load the data from the file, add header and parse date-time column\n",
    "* Show timestamp inconsistencies of the data\n",
    "* Analyse every timeseries in the data and classify if they have Gaussian distribution or not (relevant for some anomaly detection stuff)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "# main imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# skewness and kurtosis\n",
    "from scipy.stats import skew, skewtest, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install python package from the src/ folder (then you need to restart the kernel!)\n",
    "# not currently used in this file, but some functions should be copied to src/\n",
    "!cd ../.. & python setup.py build & python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the current data module (from src/)\n",
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data filename\n",
    "FILENAME = \"../../../data/raw/continental/continental_preliminary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_csv(FILENAME, header=0,\n",
    "    names=[\n",
    "        \"Id\",\n",
    "        \"Timestamp\",\n",
    "        \"SerialNumber\",\n",
    "        \"Station\",\n",
    "        \"StationType\",\n",
    "        \"StationNumber\",\n",
    "        \"Material\",\n",
    "        \"TextDescription\",\n",
    "        \"TestValue\",\n",
    "        \"TestResult\",\n",
    "        \"USL\",\n",
    "        \"LSL\",\n",
    "        \"Format\"\n",
    "    ],\n",
    "    parse_dates=[\"Timestamp\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check some basic data on the dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there seems to be something wrong with the times\n",
    "# there should only be data for a singled day; the timestamps tell another story\n",
    "df[\"Timestamp\"].dt.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 2 station types in the data\n",
    "# we have 19 stations\n",
    "# in all these stations we keep 9932 sensors\n",
    "# some stations have a couple of tests, final ST station has 5000+ checks\n",
    "df[\"TextDescription\"].unique().shape[0]\n",
    "df[\"Station\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast plot of timestamps converted to unixts; something is wrong here\n",
    "screwing_df = df[df[\"Station\"] == \"SCREWING\"]\n",
    "torque1 = screwing_df[screwing_df[\"TextDescription\"] == \"Torque 1 value\"]\n",
    "plt.plot(torque1[\"Timestamp\"].values.astype(np.int64) // 10 ** 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a nice figure of data\n",
    "plt.figure()\n",
    "plt.plot(torque1[\"TestValue\"].values)\n",
    "plt.plot(torque1[\"USL\"].values)\n",
    "plt.plot(torque1[\"LSL\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_histogram(values, title):\n",
    "    \"\"\"\n",
    "    Draws a histogram of a list of values and adds a title.\n",
    "    \"\"\"\n",
    "    min = values.min()\n",
    "    max = values.max()\n",
    "\n",
    "    bins = np.arange(min, max, (max - min) / 12)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    plt.title(title)\n",
    "    ax.hist(values, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_normal_distribution(values):\n",
    "    \"\"\"\n",
    "    The function estimates whether an array from values has a normal distribution accoring to:\n",
    "    - it has to have at least 8 examples (if not, it is classified as non-normal)\n",
    "    - it has to have pvalue in the skewness test higher that 0.05    \n",
    "    - it has to have an absolute kurtosis value greater than 0.5\n",
    "    - it has to have more than only one value in the data\n",
    "    \"\"\"\n",
    "    # do we have enough data?\n",
    "    if (values.shape[0] < 8):\n",
    "        return False\n",
    "    # skewness and kurtosis\n",
    "    pvalue = skewtest(values).pvalue\n",
    "    # kurtosis \n",
    "    kurt = kurtosis(values)\n",
    "\n",
    "    # do we only have a single value point in the data\n",
    "    if (values.min() == values.max()):\n",
    "        return True\n",
    "\n",
    "    if (pvalue < 0.05):\n",
    "        return False\n",
    "\n",
    "    if (np.abs(kurt) > 0.5):\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_histogram_if_not_normal(values):\n",
    "    \"\"\"\n",
    "    Show histogram data only if the distribution s not normal (not used).\n",
    "    \"\"\"\n",
    "    if not is_normal_distribution(values):\n",
    "        draw_histogram(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transverse_timeseries(df):\n",
    "    \"\"\"\n",
    "    Transverse through all the sensors in the data frame, and classify the distribution (either normal or non-normal).\n",
    "    Optionally, one can also draw histograms. If you uncomment this, also change the transversing as there are \n",
    "    ~11.000 different sensors. Data on the classification of time series is written in 2 log files: normal.log and\n",
    "    not_normal.log.\n",
    "    \"\"\"\n",
    "    stations = df[\"Station\"].unique()\n",
    "    for station in stations:        \n",
    "        print(\"Checking:\", station)\n",
    "        station_df = df[df[\"Station\"] == station]\n",
    "        checks = station_df[\"TextDescription\"].unique()       \n",
    "        if (checks.shape[0] > 10000):\n",
    "            print(\"Skipping; too many tests: \", checks.shape[0])\n",
    "            continue\n",
    "        for check in checks:\n",
    "            # extract values\n",
    "            check_df = station_df[station_df[\"TextDescription\"] == check]\n",
    "            values = check_df[\"TestValue\"].values\n",
    "            if not is_normal_distribution(values):                         \n",
    "                with open(\"not_normal.log\", \"a\") as fo:\n",
    "                    fo.write(\"Not normal distribution: \" + station + \" - \" + check + \"\\n\")\n",
    "                print(\"Not normal distribution:\", check)\n",
    "                # draw_histogram(values, station + \" - \" + check)\n",
    "            else:\n",
    "                with open(\"normal.log\", \"a\") as fo:\n",
    "                    fo.write(\"Normal distribution: \" + station + \" - \" + check + \"\\n\")\n",
    "                print(\"Normal distribution:\", check)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "transverse_timeseries(df)"
   ]
  }
 ]
}